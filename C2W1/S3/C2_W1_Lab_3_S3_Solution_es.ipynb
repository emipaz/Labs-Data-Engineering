{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactuando con el almacenamiento de objetos de Amazon S3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este laboratorio, trabajar√°s con el Almacenamiento de Objetos de AWS y Amazon S3. Crear√°s un bucket S3, consultar√°s datos del bucket y trabajar√°s con versionado de objetos en S3. Cargar√°s en el bucket S3 datos estructurados de un archivo CSV, datos semiestructurados de un archivo JSON y datos no estructurados de un archivo de imagen. Tambi√©n interactuar√°s con el bucket S3 a trav√©s de la consola de administraci√≥n de AWS y program√°ticamente utilizando `boto3` (el Kit de Desarrollo de Software (SDK) de AWS para Python).\n",
    "\n",
    "*Nota*: El laboratorio contiene enlaces a recursos externos. Siempre puedes echar un vistazo a estos recursos durante la sesi√≥n de laboratorio, pero no se espera que abras y leas cada enlace durante la sesi√≥n de laboratorio. Si deseas profundizar en tu comprensi√≥n, puedes revisar los recursos enlazados despu√©s de que hayas terminado con el laboratorio.\n",
    "\n",
    "Para abrir el cuaderno de soluciones, sigue estos pasos:\n",
    "- Ve al men√∫ principal y selecciona `Archivo -> Preferencias -> Configuraci√≥n`.\n",
    "- Haz clic en `Editor de Texto` a la izquierda, luego despl√°zate hacia abajo hasta la secci√≥n `Excluir archivos`.\n",
    "- Elimina la l√≠nea `**/C2_W1_Lab_3_S3_Solution.ipynb`. El archivo ahora aparecer√° en el explorador.\n",
    "- Puedes cerrar la pesta√±a `Configuraci√≥n`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabla de Contenidos\n",
    "- [ 1 - Importar Paquetes](#1)\n",
    "- [ 2 - Explorar el Conjunto de Datos](#2)\n",
    "- [ 3 - Crear un Bucket de S3](#3)\n",
    "  - [ Ejercicio 1](#ex01)\n",
    "- [ 4 - Subir y Consultar Datos](#4)\n",
    "  - [ 4.1 - Datos Estructurados](#4-1)\n",
    "  - [ 4.2 - Datos Semiestructurados](#4-2)\n",
    "    - [ Ejercicio 2](#ex02)\n",
    "    - [ Ejercicio 3](#ex03)\n",
    "  - [ 4.3 - Datos No Estructurados](#4-3)\n",
    "    - [ Ejercicio 4](#ex04)\n",
    "- [ 5 - Eliminar el Bucket](#5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "## 1 - Importar paquetes\n",
    "\n",
    "Importemos los paquetes requeridos para este laboratorio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import subprocess\n",
    "\n",
    "from typing import Any, Dict\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "## 2 - Explorar el conjunto de datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este laboratorio, se te proporcionan tres archivos de datos que puedes encontrar en la carpeta `data`. Aqu√≠ est√° la estructura de la carpeta `data`:\n",
    "\n",
    "```bash\n",
    ".\n",
    "‚îî‚îÄ‚îÄ data/\n",
    "    ‚îú‚îÄ‚îÄ csv/\n",
    "         ‚îî‚îÄ‚îÄ ratings_ml_training_dataset.csv\n",
    "    ‚îú‚îÄ‚îÄ images/\n",
    "    |    ‚îú‚îÄ‚îÄ v1/\n",
    "    |    |    ‚îî‚îÄ‚îÄ AWS-Logo.png\n",
    "    |    ‚îî‚îÄ‚îÄ v2/ \n",
    "    |    |    ‚îî‚îÄ‚îÄ AWS-Logo.png\n",
    "    ‚îî‚îÄ‚îÄ json/\n",
    "         ‚îî‚îÄ‚îÄ delivery-stream-one-record.json\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedes ver que hay tres subcarpetas (csv, im√°genes y json). Cada subcarpeta contiene un formato de datos diferente:\n",
    "- la subcarpeta csv contiene datos estructurados, almacenados en un archivo `.csv`. Estos datos consisten en el conjunto de datos de entrenamiento que se utiliz√≥ en el laboratorio de la Semana 4 del Curso 1 para entrenar el modelo del sistema de recomendaci√≥n;\n",
    "- la subcarpeta json contiene datos semiestructurados almacenados en un archivo `.json`;\n",
    "- la subcarpeta de im√°genes contiene datos no estructurados, que consisten en dos versiones del logotipo de AWS.\n",
    "\n",
    "Subir√°s estos diferentes tipos de datos a un bucket de S3 que crear√°s en este laboratorio. Aqu√≠ tienes un resumen r√°pido de la terminolog√≠a de almacenamiento de objetos de AWS:\n",
    "- Un [bucket](https://docs.aws.amazon.com/AmazonS3/latest/userguide/UsingBucket.html) es un contenedor para objetos almacenados en Amazon S3.\n",
    "- Un objeto es un archivo y cualquier metadato que describa ese archivo. Tiene un identificador √∫nico, tambi√©n conocido como clave del objeto.\n",
    "El almacenamiento de objetos permite el almacenamiento de cualquier objeto; puedes almacenar no solo datos estructurados, sino tambi√©n datos no estructurados y semiestructurados.\n",
    "\n",
    "Para cargar tus datos en Amazon S3, primero necesitas crear un bucket de S3 en una de las regiones de AWS. Y esto es lo que vas a hacer program√°ticamente en el pr√≥ximo ejercicio. Pero antes de eso, verifica que no haya buckets de S3 en tu cuenta. Ejecuta el siguiente c√≥digo para obtener la URL a la consola de AWS.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Nota*: Por razones de seguridad, la URL para acceder a la consola de AWS caducar√° cada 15 minutos, pero cualquier recurso de AWS que hayas creado seguir√° estando disponible durante el per√≠odo de 2 horas. Si necesitas acceder a la consola despu√©s de 15 minutos, vuelve a ejecutar esta celda de c√≥digo para obtener un nuevo enlace activo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../.aws/aws_console_url', 'r') as file:\n",
    "    aws_url = file.read().strip()\n",
    "\n",
    "HTML(f'<a href=\"{aws_url}\" target=\"_blank\">GO TO AWS CONSOLE</a>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora haz clic en el enlace de arriba para acceder a la consola de AWS y buscar **S3**. Deber√≠as ver que a√∫n no se han creado buckets en tu cuenta.\n",
    "\n",
    "*Nota:* Si ves la ventana como en la siguiente captura de pantalla, haz clic en el enlace **logout**, cierra la ventana y vuelve a hacer clic en el enlace de la consola.\n",
    "\n",
    "![AWSLogout](images/AWSLogout.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "## 3 - Crear un Bucket de S3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ex01'></a>\n",
    "### Ejercicio 1\n",
    "\n",
    "Para crear un bucket S3, necesitas especificar el nombre del bucket y la regi√≥n para tu bucket. En este laboratorio, la regi√≥n est√° configurada en `us-east-1`. En cuanto al nombre del bucket, los nombres de los buckets deben ser globalmente √∫nicos para evitar colisiones con buckets que otros estudiantes podr√≠an estar creando o trabajando al mismo tiempo. Para garantizar la singularidad del nombre del bucket, utilizar√°s el ID de cuenta de AWS de Vocareum para incluirlo en el nombre del bucket.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS_ACCOUNT_ID = subprocess.run(['aws', 'sts', 'get-caller-identity', '--query', 'Account', '--output', 'text'], capture_output=True, text=True).stdout.strip()\n",
    "# BUCKET_NAME = f'de-c2w1lab3-{AWS_ACCOUNT_ID}'\n",
    "AWS_DEFAULT_REGION = 'us-east-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para crear el bucket program√°ticamente en Python usando boto3, puedes utilizar el m√©todo `S3` [`create_bucket()`](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3/client/create_bucket.html) que requiere un objeto Cliente (como se explica en el laboratorio de DynamoDB).\n",
    "\n",
    "La siguiente funci√≥n `create_s3_bucket()` consiste en los pasos necesarios para crear el bucket S3 (instanciando un objeto Cliente y luego llamando al m√©todo `create_bucket()`). La funci√≥n recibe como entrada el nombre del bucket y la regi√≥n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_s3_bucket(bucket_name:str , region: str):\n",
    "    \n",
    "    # Create an S3 client\n",
    "    s3_client = boto3.client('s3', region_name=region)\n",
    "\n",
    "    # Create the S3 bucket\n",
    "    try:\n",
    "        s3_client.create_bucket(Bucket=bucket_name)\n",
    "        print(f\"S3 bucket '{bucket_name}' created successfully in region '{region}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = 'de-emi-181325975426'  # Replace with your actual bucket name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3', region_name=AWS_DEFAULT_REGION,\n",
    "                         endpoint_url='https://s3.amazonaws.com',  # üîπ Cualquier valor\n",
    "aws_access_key_id=\"ASIASUN66Z6BP4ADEOOX\",       # üîπ Cualquier valor\n",
    "aws_secret_access_key=\"72JmcA1oOMCiptSbJk+2wIragWFBLRjoZV3ZPeZ\"  # üîπ Cualquier valor\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'access_key'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m session \u001b[38;5;241m=\u001b[39m boto3\u001b[38;5;241m.\u001b[39mSession()\n\u001b[0;32m      2\u001b[0m credentials \u001b[38;5;241m=\u001b[39m session\u001b[38;5;241m.\u001b[39mget_credentials()\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccess_key\u001b[49m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(credentials\u001b[38;5;241m.\u001b[39msecret_key)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'access_key'"
     ]
    }
   ],
   "source": [
    "session = boto3.Session()\n",
    "credentials = session.get_credentials()\n",
    "print(credentials.access_key)\n",
    "print(credentials.secret_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (InvalidAccessKeyId) when calling the CreateBucket operation: The AWS Access Key Id you provided does not exist in our records.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43ms3_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_bucket\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBucket\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBUCKET_NAME\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\py313\\Lib\\site-packages\\botocore\\client.py:595\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    591\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    592\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    593\u001b[0m     )\n\u001b[0;32m    594\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[1;32m--> 595\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\py313\\Lib\\site-packages\\botocore\\context.py:123\u001b[0m, in \u001b[0;36mwith_current_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hook:\n\u001b[0;32m    122\u001b[0m     hook()\n\u001b[1;32m--> 123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\py313\\Lib\\site-packages\\botocore\\client.py:1058\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[1;34m(self, operation_name, api_params)\u001b[0m\n\u001b[0;32m   1054\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m   1055\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1056\u001b[0m     )\n\u001b[0;32m   1057\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[1;32m-> 1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[0;32m   1059\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1060\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[1;31mClientError\u001b[0m: An error occurred (InvalidAccessKeyId) when calling the CreateBucket operation: The AWS Access Key Id you provided does not exist in our records."
     ]
    }
   ],
   "source": [
    "s3_client.create_bucket(Bucket=BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: Unable to locate credentials\n"
     ]
    }
   ],
   "source": [
    "create_s3_bucket(bucket_name=BUCKET_NAME, region=AWS_DEFAULT_REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedes verificar que el bucket ha sido creado utilizando la herramienta `aws cli`. Para listar los buckets creados en tu cuenta, puedes usar el siguiente comando:\n",
    "`aws s3 ls`\n",
    "\n",
    "Puedes ejecutar el comando en la terminal o puedes ejecutarlo en este cuaderno pero necesitas agregar un signo de exclamaci√≥n `!` al principio del comando. Esto te permite ejecutar comandos de shell en una celda de c√≥digo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para enumerar los objetos almacenados dentro de un bucket, puedes usar el comando `aws s3 ls <nombre-de-tu-bucket>`. Si ejecutas este comando ahora, no se mostrar√° ning√∫n resultado ya que el bucket todav√≠a est√° vac√≠o.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls $BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tambi√©n puedes inspeccionar el bucket S3 en la Consola de AWS. Busca **S3**. Ver√°s el bucket con el nombre que proporcionaste. Puedes verificar que el bucket est√° vac√≠o simplemente haciendo clic en √©l.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "## 4 - Subir y Consultar Datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4-1'></a>\n",
    "### 4.1 - Datos Estructurados\n",
    "\n",
    "En esta secci√≥n del laboratorio, subir√°s datos estructurados al bucket S3 y luego los consultar√°s.\n",
    "\n",
    "**Subir el archivo CSV**\n",
    "\n",
    "Primero verifica el archivo `data/csv/ratings_ml_training_dataset.csv`. Cada fila en este conjunto de datos consiste en los detalles de un producto que fue comprado por un usuario dado. La fila tambi√©n contiene los detalles del usuario y qu√© calificaciones proporcionaron a ese producto (el mismo conjunto de datos que se utiliz√≥ en el laboratorio de la Semana 4 del Curso 1 para entrenar el sistema de recomendaci√≥n). Aqu√≠ est√° la estructura de esta tabla:\n",
    "\n",
    "![schema_after_ETL](images/schema_after_ETL.png \"Conjunto de datos de calificaciones\")\n",
    "\n",
    "Para subir este archivo CSV al bucket de forma program√°tica, puedes usar el m√©todo S3 [upload_file()](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3/client/upload_file.html). Este m√©todo espera tres argumentos: la ruta del archivo fuente que deseas subir (Filename), el nombre del bucket al que deseas subir (Bucket) y la clave u nombre del objeto (Key). El √∫ltimo argumento especifica c√≥mo deseas etiquetar el objeto o archivo subido dentro del bucket, este nombre debe identificar de forma √∫nica el objeto subido.\n",
    "\n",
    "La siguiente funci√≥n `upload_file_to_s3()` consiste en los pasos necesarios para subir el archivo al bucket de S3 (instanciando un objeto Cliente y luego llamando al m√©todo `upload_file()`). La funci√≥n toma como entrada la ruta al archivo local a subir, el nombre del bucket y la clave del objeto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_file_to_s3(local_file_path: str, bucket_name: str, object_key: str) -> None:\n",
    "    \"\"\"Uploads a local file to S3 using boto3\n",
    "\n",
    "    Args:\n",
    "        local_file_path (str): Local file path\n",
    "        BUCKET_NAME (str): Bucket name\n",
    "        object_key (str): the key name, which should uniquely identifies the uploaded object in the bucket\n",
    "    \"\"\"\n",
    "    # Create an S3 client\n",
    "    s3_client = boto3.client('s3')\n",
    "\n",
    "    # Upload the file to S3\n",
    "    try:\n",
    "        s3_client.upload_file(local_file_path, bucket_name, object_key)\n",
    "        print(f\"File {local_file_path} uploaded to s3://{bucket_name}/{object_key} successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading file to S3: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the local file path, and object key\n",
    "local_file_path = 'data/csv/ratings_ml_training_dataset.csv'\n",
    "object_key = 'csv/ratings_ml_training_dataset.csv'\n",
    "\n",
    "# Upload the file to S3\n",
    "upload_file_to_s3(local_file_path, BUCKET_NAME, object_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedes verificar que el archivo est√° en el bucket ya sea revisando el contenido a trav√©s de la consola de AWS o program√°ticamente tambi√©n utilizando `boto3` o incluso el `aws cli`. Ve a la consola de AWS y verifica que hay una nueva carpeta en tu bucket que contiene el archivo csv que acabas de subir.\n",
    "\n",
    "*Nota*: recuerda de la clase que el almacenamiento de objetos tiene una estructura plana. Cuando utilizas el delimitador `/` en el nombre del objeto o clave, como en este ejemplo: `object_key = 'csv/ratings_ml_training_dataset.csv'`, est√°s incluyendo un prefijo de nombre de clave que es utilizado por S3 para agrupar objetos dentro del bucket. La consola utiliza el t√©rmino `carpeta` porque este agrupamiento de objetos puede ser an√°logo a una carpeta en un sistema de archivos regular. Puedes aprender m√°s sobre las claves de objetos [aqu√≠](https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-keys.html).\n",
    "\n",
    "Si ejecutas el siguiente comando ya sea en la terminal o en la celda del notebook, tambi√©n puedes verificar que el archivo que subiste est√° all√≠. Recuerda que si lo ejecutas en una terminal, debes omitir el signo de exclamaci√≥n al principio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls $BUCKET_NAME/csv/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Consultar los datos**\n",
    "\n",
    "Puede consultar los datos de sus archivos csv utilizando AWS Athena. Esto es algo que ha hecho en laboratorios anteriores como en la Tarea C1W2 y seguir√° haci√©ndolo en futuros laboratorios. En general, AWS Athena permite consultar datos en diferentes formatos, como parquet, tsv, csv, etc. Como seguir√° consultando datos con Athena en futuros laboratorios, para este laboratorio en particular solo se le dirigir√° a alguna documentaci√≥n que puede leer para tener algunas ideas al respecto:\n",
    "\n",
    "- [Consulta de datos desde la consola de AWS](https://builtin.com/articles/aws-architecture-athena-query-csv-table-stored-s3)\n",
    "- [Consulta de datos desde m√∫ltiples fuentes en el foro de AWS](https://repost.aws/questions/QUeZq3d77YQ8-9EPtDDBe6RQ/query-data-from-multiple-sources-in-s3-on-athena)\n",
    "- [Uso de delimitadores en la documentaci√≥n de AWS](https://docs.aws.amazon.com/athena/latest/ug/lazy-simple-serde.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4-2'></a>\n",
    "### 4.2 - Datos Semiestructurados\n",
    "\n",
    "Ahora trabajar√°s con datos semiestructurados, en particular con un archivo JSON. Subir√°s el archivo ubicado en `data/json/delivery-stream-one-record.json`. Este archivo consiste en los datos obtenidos a partir de las transformaciones realizadas a los datos de transmisi√≥n en el laboratorio de la Semana 4 del Curso 1. Puedes abrirlo para verificar su estructura.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ex02'></a>\n",
    "### Ejercicio 2\n",
    "\n",
    "Completa el c√≥digo a continuaci√≥n para cargar el archivo ubicado en `data/json/delivery-stream-one-record.json` al bucket de S3 utilizando la misma funci√≥n utilizada para el archivo CSV anterior. Pero ahora en el bucket de S3, apunta a una nueva carpeta `json`, dando el mismo nombre al archivo (es decir, la clave del objeto deber√≠a comenzar con \"json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ### (~ 3 lines of code)\n",
    "# Define the local file path, and S3 key\n",
    "local_file_path_json = 'data/json/delivery-stream-one-record.json' # @REPLACE EQUALS None\n",
    "object_key_json = 'json/delivery-stream-one-record.json' # @REPLACE EQUALS None\n",
    "\n",
    "# Upload the file to S3\n",
    "upload_file_to_s3(local_file_path_json, BUCKET_NAME, object_key_json) # @REPLACE upload_file_to_s3(None, None, None)\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ex03'></a>\n",
    "### Ejercicio 3\n",
    "\n",
    "Verifique nuevamente que el archivo haya sido cargado utilizando la herramienta `aws cli`. Complete el comando apuntando a la carpeta correspondiente donde se ha cargado el archivo JSON.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ### (~ 1 line of code)\n",
    "!aws s3 ls $BUCKET_NAME/json/ # @REPLACE !aws None None None/None/\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tambi√©n puedes verificar visualmente en la consola de AWS que el archivo JSON se ha creado en el bucket. Ahora, en lugar de consultar el archivo JSON, lo descargar√°s utilizando el m√©todo `S3` [download_file()](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3/client/download_file.html), que se llama en la siguiente funci√≥n proporcionada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_object_from_s3(bucket_name: str, object_key: str, local_file_path: str) -> None:\n",
    "    \"\"\"Downloads object from S3 using boto3\n",
    "\n",
    "    Args:\n",
    "        bucket_name (str): Bucket name\n",
    "        object_key (str): Object key in S3.\n",
    "        local_file_path (str): Path in the local file system to put the downloaded object.\n",
    "    \"\"\"\n",
    "    # Create an S3 client\n",
    "    s3_client = boto3.client('s3')\n",
    "    \n",
    "    try:\n",
    "        # Download the file to a local directory\n",
    "        s3_client.download_file(bucket_name, object_key, local_file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading or printing JSON file: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecuta la siguiente celda para crear una carpeta `downloads` en tu sistema de archivos local, y luego llama a la funci√≥n `download_object_from_s3` para descargar el archivo JSON desde tu bucket de S3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir 'downloads'\n",
    "local_file_path = './downloads/delivery-stream-one-record.json'\n",
    "\n",
    "download_object_from_s3(bucket_name=BUCKET_NAME, object_key=object_key_json, local_file_path=local_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que el archivo haya sido descargado, puedes leer su contenido desde el sistema de archivos local:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(local_file_path, 'r') as file:    \n",
    "    json_content = json.loads(file.read())\n",
    "    print(json_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora puedes trabajar con este objeto en particular si necesitas hacer alguna transformaci√≥n.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4-3'></a>\n",
    "### 4.3 - Datos no Estructurados\n",
    "\n",
    "Finalmente, trabajar√°s con datos no estructurados. Subir√°s una imagen al bucket y, esta vez, la descargar√°s desde un navegador (para mostrarte las diversas formas en que puedes descargar objetos de un bucket de S3). Por defecto, un bucket de S3 y sus objetos son privados. Para poder descargar objetos de S3 desde un navegador, tendr√°s que realizar algunas modificaciones en el bucket para hacer que algunos de sus objetos est√©n disponibles para lectura p√∫blica.\n",
    "\n",
    "Primero, necesitas configurar el bucket para aceptar pol√≠ticas p√∫blicas y Listas de Control de Acceso (ACL) p√∫blicas. Para hacerlo, utilizar√°s el m√©todo `S3 put_public_access_block`. Para entender qu√© espera este m√©todo como argumentos, consulta la siguiente [documentaci√≥n](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3/client/put_public_access_block.html).\n",
    "\n",
    "Ejecuta las siguientes dos celdas para cambiar la configuraci√≥n de acceso del bucket de S3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s3_public_access_setup(bucket_name: str, public_access_block_configuration: Dict[str, Any]) -> None:\n",
    "    \"\"\"Sets public access configuration for S3 bucket\n",
    "\n",
    "    Args:\n",
    "        bucket_name (str): Bucket name\n",
    "        public_access_block_configuration (Dict[str, Any]): Configuration for public access\n",
    "    \"\"\"\n",
    "    \n",
    "    s3_client = boto3.client('s3')\n",
    "    \n",
    "    # Update the bucket's public access settings\n",
    "    s3_client.put_public_access_block(\n",
    "        Bucket=bucket_name,\n",
    "        PublicAccessBlockConfiguration=public_access_block_configuration\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the public access settings  \n",
    "public_access_configuration = {\n",
    "    'BlockPublicAcls': False,\n",
    "    'IgnorePublicAcls': False,\n",
    "    'BlockPublicPolicy': False,\n",
    "    'RestrictPublicBuckets': False\n",
    "}\n",
    "\n",
    "s3_public_access_setup(bucket_name=BUCKET_NAME, \n",
    "                       public_access_block_configuration=public_access_configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acabas de modificar el bucket para que ahora acepte reglas de acceso p√∫blico a sus objetos. Ahora adjuntar√°s una pol√≠tica al bucket para permitir que cualquier persona en Internet tenga acceso de lectura a los objetos cuya clave comience con `images/`. (\"Una pol√≠tica es un objeto en AWS que, cuando se asocia con una identidad o recurso, define sus permisos\", [referencia](https://docs.aws.amazon.com/IAM/latest/UserGuide/introduction_access-management.html). Aprender√°s m√°s sobre las pol√≠ticas en la siguiente lecci√≥n o puedes consultar la documentaci√≥n [aqu√≠](https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html)).\n",
    "\n",
    "Para adjuntar la pol√≠tica mencionada al bucket de S3, utilizar√°s el m√©todo `put_bucket_policy()` de `S3`, definir√°s los detalles de la pol√≠tica y pasar√°s la pol√≠tica a `S3 put_bucket_policy()`. Ejecuta las siguientes tres celdas para adjuntar la pol√≠tica adecuada al bucket de S3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s3_put_bucket_policy(bucket_name: str, policy: Dict[str, Any]) -> None:\n",
    "    \"\"\"Allows to put bucket policies\n",
    "\n",
    "    Args:\n",
    "        bucket_name (str): Bucket name\n",
    "        policy (Dict[str, Any]): Bucket policy\n",
    "    \"\"\"\n",
    "    \n",
    "    s3_client = boto3.client('s3')\n",
    "    response = s3_client.put_bucket_policy(Bucket=bucket_name, Policy=json.dumps(policy))\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = { \n",
    "    \"Version\": \"2012-10-17\", \n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": \"*\",\n",
    "            \"Action\": \"s3:GetObject\",\n",
    "            \"Resource\": f\"arn:aws:s3:::{BUCKET_NAME}/images/*\"\n",
    "        }\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta pol√≠tica permite que cualquier persona (`\"Principal\": \"*\"`) utilice el m√©todo `S3 GetObject` en `{BUCKET_NAME}/images/`, es decir, para recuperar objetos almacenados en su cubo S3 y cuyo clave/nombre comienza con `images/`. Puede obtener m√°s informaci√≥n sobre dicha pol√≠tica [aqu√≠](https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html#access_policies-json).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = s3_put_bucket_policy(bucket_name=BUCKET_NAME, policy=policy) \n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ex04'></a>\n",
    "### Ejercicio 4\n",
    "\n",
    "Ahora, vamos a subir la imagen ubicada en `data/images/v1/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_file_path_image_v1 = 'data/images/v1/AWS-Logo.png'\n",
    "object_key_image = 'images/AWS-Logo.png'\n",
    "\n",
    "upload_file_to_s3(local_file_path_image_v1, BUCKET_NAME, object_key_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifique que la imagen haya sido cargada. Complete el comando a continuaci√≥n. Recuerde apuntar a la carpeta correcta en S3 para listar solo el archivo que acaba de cargar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ### (~ 1 line of code)\n",
    "!aws s3 ls $BUCKET_NAME/images/ # @REPLACE !aws None None None/None/\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ve al panel de control de AWS y busca **S3**. En tu bucket, haz clic en im√°genes y luego en el nombre de la imagen que acabas de subir. Ver√°s una opci√≥n llamada `URL del objeto`. Si la copias y la pegas en una nueva pesta√±a del navegador, deber√≠as poder descargar el archivo.\n",
    "\n",
    "<img src=\"images/object_url.png\" width=\"500\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos c√≥mo funciona la versi√≥n de cubo. Primero necesitas habilitar esta funci√≥n en tu cubo llamando al m√©todo `S3` [put_bucket_versioning()](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3/client/put_bucket_versioning.html) y activando la versi√≥n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_bucket_versioning(bucket_name: str, versioning_config: Dict[str, str]) -> Dict[Any, Any]:\n",
    "    \n",
    "    s3_client = boto3.client('s3')\n",
    "\n",
    "    # Enable bucket versioning\n",
    "    response = s3_client.put_bucket_versioning(\n",
    "        Bucket=bucket_name,\n",
    "        VersioningConfiguration=versioning_config\n",
    "    )\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "versioning_config = {'Status': 'Enabled'}\n",
    "\n",
    "response = configure_bucket_versioning(bucket_name=BUCKET_NAME, \n",
    "                                       versioning_config=versioning_config)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a subir la segunda versi√≥n del logo de AWS ubicado en `data/images/v2/AWS-Logo.png` y usar la misma clave u nombre de objeto que usaste para la imagen anterior:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_file_path_image_v2 = 'data/images/v2/AWS-Logo.png'\n",
    "object_key_image = 'images/AWS-Logo.png'\n",
    "\n",
    "upload_file_to_s3(local_file_path_image_v2, BUCKET_NAME, object_key_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta ahora, has enumerado el contenido del bucket utilizando la herramienta `aws cli`. Tambi√©n puedes enumerar el contenido en Python utilizando `S3` [list_objects_v2()](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3/client/list_objects_v2.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_objects_in_folder(bucket_name: str, prefix_key: str):\n",
    "    # Create an S3 client\n",
    "    s3_client = boto3.client('s3')\n",
    "\n",
    "    # Use list_objects_v2 to list objects in the specified folder\n",
    "    response = s3_client.list_objects_v2(\n",
    "        Bucket=bucket_name,\n",
    "        Prefix=prefix_key\n",
    "    )\n",
    "\n",
    "    # Check if objects were found\n",
    "    if 'Contents' in response:\n",
    "        # Print each object's key\n",
    "        print(\"Objects with a key that starts with '{}':\".format(prefix_key))\n",
    "        for obj in response['Contents']:\n",
    "            print(obj['Key'])\n",
    "    else:\n",
    "        print(\"No objects found in folder '{}'.\".format(prefix_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_objects_in_folder(bucket_name=BUCKET_NAME, prefix_key='images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este m√©todo solo muestra los archivos cuya clave comienza con un prefijo particular, pero no puedes ver nada acerca de sus versiones. Para eso, usemos el m√©todo [`S3 list_object_versions()`](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3/client/list_object_versions.html) en su lugar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_object_versions(bucket_name: str, prefix_key: str) -> None:\n",
    "    # Create an S3 client\n",
    "    s3_client = boto3.client('s3')\n",
    "\n",
    "    # List object versions\n",
    "    response = s3_client.list_object_versions(Bucket=bucket_name, Prefix=prefix_key)\n",
    "\n",
    "    # Process the response to get object versions\n",
    "    for version in response.get('Versions', []):\n",
    "        print(\"Object Key:\", version['Key'])\n",
    "        print(\"Object Version Id:\", version['VersionId'])\n",
    "        print(\"Is Latest:\", version['IsLatest'])\n",
    "        print(\"Last Modified:\", version['LastModified'])\n",
    "        print()\n",
    "\n",
    "list_object_versions(bucket_name=BUCKET_NAME, prefix_key='images/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, regresa al bucket de S3 en la consola de AWS y busca el archivo que acabas de subir. Obt√©n su URL de objeto para descargar la nueva versi√≥n del archivo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5'></a>\n",
    "## 5 - Eliminar el Bucket\n",
    "\n",
    "Para eliminar el bucket, es necesario asegurarse de que est√© vac√≠o antes del proceso de eliminaci√≥n. Y para eso, hay dos m√©todos que puedes utilizar: `S3` [delete_object()](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3/client/delete_object.html) y `S3` [delete_bucket()](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3/client/delete_bucket.html).\n",
    "\n",
    "En la siguiente celda, se proporciona una funci√≥n que hace uso de `S3 delete_object()` y `S3 delete_bucket()`. Esta funci√≥n toma como entrada el par√°metro booleano `delete_objects`; este par√°metro booleano se utiliza para indicar si el bucket est√° vac√≠o o no. Si el bucket contiene objetos, entonces la funci√≥n primero elimina los objetos y luego el bucket. De lo contrario, la funci√≥n elimina directamente el bucket. Ten en cuenta que debes eliminar todas las versiones de los objetos. La eliminaci√≥n de versiones es necesaria solo si has habilitado el control de versiones del bucket. Adem√°s, la funci√≥n tambi√©n elimina los marcadores de eliminaci√≥n. Estos son marcadores de posici√≥n que se crean despu√©s de eliminar objetos en un bucket habilitado para versiones. Puedes obtener m√°s informaci√≥n sobre ellos [aqu√≠](https://www.learnaws.org/2022/10/04/aws-s3-delete-marker/#what-is-an-aws-s3-delete-marker).\n",
    "\n",
    "**Nota:** Es importante tener en cuenta que cuando est√°s trabajando con buckets de S3 en entornos reales y de producci√≥n, NO DEBES eliminarlos ni eliminar los objetos dentro de ellos a menos que est√©s completamente seguro de lo que est√°s haciendo. Aseg√∫rate de que el bucket/objetos ya no sean utilizados por ning√∫n proceso aguas arriba o aguas abajo. Esto es algo que debes hacer con precauci√≥n y despu√©s de hablar con los propietarios del bucket/objeto, las partes interesadas y otros propietarios de procesos que puedan depender de la informaci√≥n alojada en ese bucket.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s3_delete_bucket(bucket_name: str, delete_objects: bool) -> Dict[Any, Any]:\n",
    "    s3_client = boto3.client('s3')\n",
    "    \n",
    "    if delete_objects:\n",
    "        # List all versions of all objects in the bucket\n",
    "        response = s3_client.list_object_versions(Bucket=bucket_name)\n",
    "        \n",
    "        # Delete all object versions\n",
    "        for version in response.get('Versions', []):\n",
    "            key = version['Key']\n",
    "            version_id = version['VersionId']\n",
    "            s3_client.delete_object(Bucket=bucket_name, Key=key, VersionId=version_id)\n",
    "        \n",
    "        # Delete all delete markers\n",
    "        for delete_marker in response.get('DeleteMarkers', []):\n",
    "            key = delete_marker['Key']\n",
    "            version_id = delete_marker['VersionId']\n",
    "            s3_client.delete_object(Bucket=bucket_name, Key=key, VersionId=version_id)        \n",
    "    \n",
    "    # Delete the bucket\n",
    "    response = s3_client.delete_bucket(\n",
    "        Bucket=bucket_name\n",
    "    )\n",
    "\n",
    "    return response\n",
    "\n",
    "response = s3_delete_bucket(bucket_name=BUCKET_NAME, delete_objects=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, verifica que el bucket ya no existe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¬°Bien hecho! Aprendiste c√≥mo trabajar con Amazon S3, como por ejemplo c√≥mo crear buckets de S3, subir archivos a buckets de S3 y entender algunas de sus caracter√≠sticas como la versi√≥n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py313",
   "language": "python",
   "name": "py313"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "0f7c385fa1e05902489312e0f26958bd15563da08ffbc61abb00afd1f64e2ab3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
