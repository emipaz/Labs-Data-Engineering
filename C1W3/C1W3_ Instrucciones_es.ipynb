{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acf56f44-84fb-435c-8211-257521d4d39b",
   "metadata": {},
   "source": [
    "# Tarea de la Semana 3:<br>Buena Arquitectura de Datos\n",
    "\n",
    "¡Bienvenido al laboratorio de la semana 3! En este laboratorio, explorarás y evaluarás los aspectos de seguridad, rendimiento, confiabilidad y escalabilidad de una aplicación web alojada en AWS. Harás esto simulando tráfico hacia tu aplicación web y utilizando herramientas de AWS como Amazon CloudWatch para monitorear los recursos informáticos y la actividad de red en tu aplicación web. Configurarás los recursos informáticos para habilitar la eficiencia de rendimiento, así como opciones de seguridad para controlar el tráfico entrante a tu aplicación web. Realizarás estas tareas a través de los principios de una \"buena\" arquitectura de datos, así como a través de las lentes del Marco Bien Arquitectado de AWS. Al pasar por este laboratorio, obtendrás una comprensión de los recursos primitivos disponibles en AWS, para que luego puedas aplicar esta comprensión al diseñar tus canalizaciones de datos como Ingeniero de Datos.\n",
    "\n",
    "# Tabla de Contenidos\n",
    "- [1 - Introducción](#1)\n",
    "- [2 - Obteniendo la Dirección de la Aplicación Web](#2)\n",
    "- [3 - Monitoreo del Uso de CPU y Actividad de Red](#3)\n",
    "- [4 - Mejorando la Seguridad](#4)\n",
    "- [5 - Verificando la Disponibilidad de EC2](#5)\n",
    "- [6 - Realizando Escalado Automático](#6)\n",
    "    - [6.1 - Utilizando Recursos de Manera Eficiente](#6-1)\n",
    "    - [6.2 - Realizando Escalado Automático](#6-2)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a43dcb-1233-4a42-8b2c-5ff02c7d7071",
   "metadata": {},
   "source": [
    "<div id='1'/>\n",
    "\n",
    "## 1 - Introducción\n",
    "\n",
    "En la semana 2, implementaste un pipeline de datos donde ingresaste y transformaste datos y luego los serviste a un analista de datos.\n",
    "\n",
    "![image alt ><](./images/ETL.drawio.png)\n",
    "\n",
    "Ahora supongamos que construiste un pipeline de datos similar para servir los datos transformados a un público más amplio. Por ejemplo, supongamos que tu empresa vende algunos datos analíticos y los pone a disposición de personas en todo internet. O supongamos que necesita servir algunos paneles incrustados a sus clientes. Para hacerlo, necesitarás construir una aplicación web que ponga los datos o paneles a disposición de sus clientes previstos y que sea capaz de escalar según sus necesidades. En este laboratorio, te enfocarás en este componente de tu arquitectura de datos (la aplicación web) para evaluar su seguridad, rendimiento, confiabilidad y escalabilidad.\n",
    "\n",
    "¿Cómo se crea la aplicación web? Una forma típica de implementar soluciones de aplicaciones web es utilizar una [arquitectura de tres capas](https://docs.aws.amazon.com/whitepapers/latest/serverless-multi-tier-architectures-api-gateway-lambda/three-tier-architecture-overview.html) que consta de tres capas o niveles:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d76075-d7cf-4ec1-9566-924d7ae88974",
   "metadata": {},
   "source": [
    "- **Capa de presentación**: esta capa representa la interfaz de usuario del sitio web (por ejemplo, una página web) que permite a los clientes interactuar con la aplicación web utilizando sus dispositivos. Aquí es donde se pueden mostrar los paneles analíticos para los clientes.\n",
    "- **Capa lógica**: esta capa, también conocida como capa de aplicación, representa la lógica empresarial que procesa la entrada de los clientes, realiza consultas a los almacenes de datos internos y devuelve los resultados que deben mostrarse en la capa de presentación.\n",
    "- **Capa de datos**: esta capa es donde se almacenan los datos asociados con la aplicación web.\n",
    "\n",
    "Aquí se te presenta la arquitectura de tres capas de tu aplicación web, y principalmente interactuarás con los recursos informáticos en los que se ejecuta la lógica de la aplicación. Aquí tienes el diagrama arquitectónico de la aplicación web:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1de4a54-5e75-462c-9533-b35923ae1e56",
   "metadata": {},
   "source": [
    "En el lado izquierdo, se ve S3 que representa el almacén de datos de la capa de datos, solo como un ejemplo de una capa de datos. En el lado derecho, se ven los clientes que interactúan con el sitio web a través de sus dispositivos. Los otros dos componentes principales son **Application Load Balancer (ALB)** y **Auto Scaling group** que operan en la capa de aplicación:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4de6ec-0537-4ff9-8652-b6bd68bd20e5",
   "metadata": {},
   "source": [
    "- [Grupo de escalado automático de Amazon EC2](https://docs.aws.amazon.com/autoscaling/ec2/userguide/what-is-amazon-ec2-auto-scaling.html): este grupo consiste en una colección de instancias de EC2. ¿Qué es una instancia de EC2? Este es el servidor de aplicaciones en el que se ejecuta la lógica de tu aplicación. Principalmente consiste en la Unidad Central de Procesamiento (CPU) y la Memoria de Acceso Aleatorio (RAM). Piensa en EC2 como una computadora proporcionada por AWS en la que ejecutarás tu código. ¿Por qué tendrías más de una EC2? Cada EC2 ejecuta la misma lógica y se utilizan para aumentar las capacidades informáticas de tu aplicación. Entonces, en lugar de tener una sola EC2 que procesa todas las entradas o solicitudes de los clientes, estas entradas se distribuyen entre las instancias de EC2. **Escalado automático** significa que el número de instancias de EC2 puede aumentar o disminuir según la demanda. En este caso, se trata de las entradas o solicitudes de los clientes a la aplicación web.\n",
    "\n",
    "- [Balanceador de carga de aplicaciones](https://docs.aws.amazon.com/elasticloadbalancing/latest/userguide/what-is-load-balancing.html): El grupo de escalado automático está asociado con un balanceador de carga de aplicaciones, que distribuye el tráfico de aplicaciones entrante (solicitudes de clientes o entradas) entre las instancias de EC2. El balanceador de carga sirve como el único punto de contacto para los clientes.\n",
    "\n",
    "En el diagrama, también se ven dos términos: **Red Privada Virtual (VPC)** y **subred**. VPC es una forma de aislar tus recursos (por ejemplo, EC2) del mundo exterior. Piénsalo como una caja o una pared que protege tus recursos, y también como una forma de organizarlos. Los recursos dentro de la VPC pueden comunicarse entre sí. Pero por defecto, no hay comunicación entre la VPC y el internet exterior a menos que permitas que esta comunicación ocurra configurando adecuadamente la VPC. Ahora, dentro de tu VPC, es posible que necesites que algunos recursos sean públicos y que otros sean privados. ¿Cómo puedes hacer eso? Este es el papel de las subredes que puedes crear dentro de tu VPC. Las subredes te proporcionan un control más detallado sobre el acceso a tus recursos. Puedes crear una **subred pública** si deseas permitir que el tráfico exterior acceda a tus recursos, y puedes crear una **subred privada** si no deseas permitir que el tráfico exterior acceda a tus recursos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137a0d38-4ef2-4190-96c8-daeefe0d45d5",
   "metadata": {},
   "source": [
    "<div id='2'/>\n",
    "\n",
    "## 2 - Obteniendo la dirección de la aplicación web\n",
    "\n",
    "La arquitectura de la aplicación web está implementada y se proporciona en este laboratorio. Tu primera tarea es obtener la dirección de tu aplicación web. Para hacerlo, necesitas encontrar el ALB, ya que sirve como el único punto de contacto para los clientes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd17e361-177d-4e1b-8e62-07fb20cac705",
   "metadata": {},
   "source": [
    "2.1. Para acceder a la consola de AWS, ejecuta el siguiente comando en la terminal.\n",
    "Si es necesario, abre una nueva terminal seleccionando Terminal > Nueva terminal en el menú.\n",
    "\n",
    "```bash\n",
    "cat ../.aws/aws_console_url\n",
    "```\n",
    "Abre el enlace en una nueva ventana del navegador.\n",
    "\n",
    "*Nota*: Por razones de seguridad, la URL para acceder a la consola de AWS caducará cada 15 minutos, \n",
    "pero cualquier recurso de AWS que hayas creado seguirá disponible durante el período de 2 horas. \n",
    "Si necesitas acceder a la consola después de 15 minutos, vuelve a ejecutar el comando para obtener un nuevo enlace activo.\n",
    "\n",
    "*Nota:* Si ves la ventana como en la siguiente captura de pantalla, haz clic en el enlace **cerrar sesión**, \n",
    "cierra la ventana y haz clic en el enlace de la consola nuevamente.\n",
    "\n",
    "![AWSLogout](images/AWSLogout.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50319d5c-7d00-43f3-9840-ebe993f803f6",
   "metadata": {},
   "source": [
    "2.2. Para encontrar el Balanceador de Carga de Aplicaciones (ALB) que se ha creado como parte de la arquitectura de tu aplicación, ve a la consola de AWS y busca **EC2**.\n",
    "\n",
    "![imagen alt ><](./images/EC2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379ee07e-def4-4fe1-a59d-c61ca5f99a66",
   "metadata": {},
   "source": [
    "2.3. En el panel izquierdo, haz clic en **Balanceadores de carga** (parte inferior del panel)\n",
    "\n",
    "![image alt ><](./images/LoadBalancers.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17dcd13e-074e-4009-88a8-56ad5a00c0a8",
   "metadata": {},
   "source": [
    "2.4. Verás un balanceador de carga llamado `de-c1w3-alb`. Copia el campo `Nombre DNS`. DNS significa Sistema de Nombres de Dominio que traduce nombres de dominio como ejemplo.com en una dirección IP \n",
    "(puedes leer más sobre DNS [aquí](https://aws.amazon.com/route53/what-is-dns/)).\n",
    "\n",
    "![imagen alt ><](./images/LoadBalancerDNS.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5b7a76-c381-43ca-88b4-d4dd7c235dc3",
   "metadata": {},
   "source": [
    "2.5. Abre una nueva ventana del navegador y pega el Nombre DNS. Verás el siguiente mensaje mostrado en la página web.\n",
    "\n",
    "*Nota*: Después de copiar el nombre DNS en el paso 2.4 y pegarlo en una nueva pestaña del navegador, es posible que te encuentres con un error de \"Este sitio no puede ser alcanzado\".\n",
    "Verifica si el navegador está intentando usar el protocolo HTTPS (`https://`). Si es así, cambia manualmente la URL para utilizar en su lugar el protocolo HTTP (`http://`).\n",
    "\n",
    "![imagen alt ><](./images/DashboardOriginal.png)\n",
    "\n",
    "La página web debería mostrar un panel de control para clientes, pero por brevedad y simplicidad, se te muestra un mensaje simple. No te preocupes por los detalles de este mensaje, \n",
    "los explorarás en una sección posterior de este laboratorio. Al abrir la página web, enviaste una solicitud HTTP al ALB. La solicitud HTTP llegó al ALB a través del puerto 80, \n",
    "que es el [puerto predeterminado](https://www.techopedia.com/definition/15709/port-80#:~:text=To%20make%20it%20convenient%20for,Port%2080%20should%20be%20used) para solicitudes HTTP \n",
    "(si no sabes qué significa puerto, consulta [aquí](https://www.cloudflare.com/learning/network-layer/what-is-a-computer-port/)).\n",
    "\n",
    "En las siguientes secciones, aprenderás cómo monitorear la actividad informática y de red de tu aplicación web y te asegurarás de que los principios de una arquitectura de datos \"buena\" estén en su lugar. \n",
    "En particular, configurarás tu arquitectura para abrazar los siguientes principios: \"Priorizar la seguridad\", \"Planificar para el fallo\" y \"Arquitecturar para la escalabilidad\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7f1bb3-4958-4670-af3b-6030f4e3d3ef",
   "metadata": {},
   "source": [
    "## 3 - Monitoreo del uso de CPU y actividad de red\n",
    "\n",
    "Cuando compartes tu aplicación web con tus clientes, debes esperar un cierto tráfico entrante a tu aplicación que necesita ser procesado. Para asegurarte de que tu aplicación pueda \n",
    "soportar las demandas entrantes, necesitarías monitorear el uso de los recursos informáticos de tu aplicación web. Para hacerlo, puedes utilizar Amazon CloudWatch, que es el servicio de monitoreo \n",
    "y observabilidad en AWS que te permite recopilar y rastrear métricas de cómputo y memoria para tu aplicación web.\n",
    "\n",
    "Monitorear el uso de los recursos informáticos de tu aplicación web es una de las prácticas del subyacente DataOps y del pilar de Excelencia Operativa del \n",
    "[Marco de trabajo bien arquitectado de AWS](https://aws.amazon.com/architecture/well-architected/?wa-lens-whitepapers.sort-by=item.additionalFields.sortDate&wa-lens-whitepapers.sort-order=desc&wa-guidance-whitepapers.sort-by=item.additionalFields.sortDate&wa-guidance-whitepapers.sort-order=desc). \n",
    "Estas prácticas enfatizan la importancia de integrar la automatización, el monitoreo de sistemas y la adaptabilidad en el diseño de cargas de trabajo en la nube. Estas prácticas permiten comprender \n",
    "tus cargas de trabajo y sus comportamientos anticipados.\n",
    "\n",
    "En esta sección, vas a realizar algunas pruebas de estrés para simular tráfico a tu sitio web y luego monitorear el uso de CPU y la actividad de red utilizando Amazon CloudWatch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35367b41-ad57-4acd-90db-06278a2ea240",
   "metadata": {},
   "source": [
    "3.1. Para realizar pruebas de estrés sobre su arquitectura actual, utilizará una herramienta de evaluación de código abierto llamada [Apache Benchmark](https://httpd.apache.org/docs/2.4/programs/ab.html).\n",
    "Esta herramienta se utiliza para probar la capacidad de un sitio web para manejar un gran número de solicitudes HTTP al mismo tiempo.\n",
    "\n",
    "En la consola de AWS, busque el servicio **CloudShell**:\n",
    "\n",
    "![image alt ><](./images/CloudShell.png)\n",
    "\n",
    "AWS CloudShell es un shell basado en el navegador que facilita la gestión, exploración e interacción segura con sus recursos de AWS.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb22865f-a822-4ac6-a5af-1a102cd9f19b",
   "metadata": {},
   "source": [
    "3.2. Instalar la herramienta Apache Benchmark con el comando de terminal (la opción `-y` permite confirmar automáticamente la instalación del paquete sin intervención manual):\n",
    "\n",
    "```bash\n",
    "sudo yum install httpd-tools -y\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63efa5ee-1cc0-4db7-ae3b-5cea95add8df",
   "metadata": {},
   "source": [
    "3.3. Para generar una prueba de estrés en tu servidor, necesitarás realizar múltiples solicitudes HTTP GET con cierta concurrencia, es decir, que las solicitudes se ejecuten al mismo tiempo.\n",
    "Esto se puede hacer con el comando `ab` de Apache Benchmark.\n",
    "Ejecuta el siguiente comando, reemplazando `ALB-DNS` con el `Nombre DNS` de tu ALB (debería estar en la dirección de la ventana del navegador donde viste la representación del panel de control).\n",
    "\n",
    "```bash\n",
    "ab -n 7000 -c 50 http://<ALB-DNS>/\n",
    "```\n",
    "\n",
    "Asegúrate de agregar la ruta `/` al final. Las opciones utilizadas en el comando se utilizan con los siguientes propósitos:\n",
    "\n",
    "- La opción `-n` corresponde al número total de solicitudes que se enviarán al servidor HTTP.\n",
    "- La opción `-c` corresponde al número de solicitudes concurrentes (simultáneas) que se realizarán.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146df6f3-233c-49fc-9e78-bb2fc295f68d",
   "metadata": {},
   "source": [
    "3.4. Para monitorear el uso de la CPU y la red, ve a los **Grupos de escalado automático** en la consola de AWS (es parte de la sección de EC2):\n",
    "\n",
    "![image alt ><](./images/AutoScalingGroups.png)\n",
    "\n",
    "\n",
    "3.5. Selecciona el grupo de escalado automático creado para ti y selecciona la pestaña de **Monitoreo** y luego haz clic en **EC2**:\n",
    "\n",
    "![image alt ><](./images/Monitoring.png)\n",
    "\n",
    "Allí puedes ver algunas de las métricas disponibles que se miden, que incluyen CPU, Red (entrante y saliente), entre otros. \n",
    "Durante la prueba, puedes verificar los gráficos de CPU y Red para ver un aumento en las métricas; las actualizaciones de los gráficos pueden tardar un tiempo ya que las métricas en AWS CloudWatch tienen una latencia de 5-10 minutos. \n",
    "Necesitarás hacer clic en el botón ![](./images/Refresh.png) para ver las actualizaciones.\n",
    "Hay otras métricas disponibles y la posibilidad de definir nuevas a través de AWS CloudWatch.\n",
    "\n",
    "AWS CloudWatch es el servicio de monitoreo y observabilidad en AWS que permite a los usuarios recopilar y rastrear métricas, recopilar y monitorear archivos de registro, y establecer alarmas. \n",
    "Está diseñado para proporcionar una vista integral de los recursos de AWS, aplicaciones y servicios que se ejecutan en la infraestructura de AWS.\n",
    "\n",
    "Después de que se realicen todas las solicitudes, deberías notar una reducción en la actividad de la CPU, así como en la red.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cf45d9-0207-4d02-9481-89d67abb568d",
   "metadata": {},
   "source": [
    "<div id='4'/>\n",
    "\n",
    "## 4 - Mejorando la seguridad\n",
    "\n",
    "Ahora que sabes cómo monitorear los recursos informáticos de tu aplicación, es hora de adentrarte en el aspecto de seguridad de tus servidores. La seguridad siempre debe ser tu prioridad, como se establece en el principio \"priorizar la seguridad\". Además, el pilar de seguridad proporciona información sobre cómo aprovechar las tecnologías en la nube para asegurar datos, sistemas y activos, y protegerlos de accesos no autorizados.\n",
    "\n",
    "Te han informado que a través del puerto 90 del ALB se muestra ciertos datos privados, pero solo ciertas personas dentro de tu empresa deberían tener acceso a ellos. En esta sección, resolverás este problema para que cualquier tráfico entrante solo pueda pasar a través del puerto 80. En particular, trabajarás ajustando los **grupos de seguridad** del ALB, que es una herramienta que actúa como un cortafuegos virtual, controlando el tráfico entrante y saliente a través del ALB.\n",
    "\n",
    "4.1. Toma el `Nombre DNS` de tu ALB y pégalo en la barra de búsqueda de tu navegador apuntando al puerto 90, de la siguiente manera:\n",
    "\n",
    "```\n",
    "<DNS-ALB>:90\n",
    "```\n",
    "\n",
    "A través de este puerto, verás un mensaje que imita la visualización de algunos datos privados. Te sorprende dado los requisitos de seguridad que deberían haber sido implementados, así que decides solucionarlo ahora.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921c8344-2f41-401f-9d06-c38b2cb3a468",
   "metadata": {},
   "source": [
    "4.2. En la consola de AWS, nuevamente buscas **EC2** y luego haces clic en **Grupos de seguridad** en el panel izquierdo.\n",
    "\n",
    "![image alt ><](./images/SecurityGroups.png)\n",
    "\n",
    "Verás una lista de grupos de seguridad, con los cuales trabajarás con los siguientes:\n",
    "- `de-c1w3-ec2-sg`: Este es el grupo de seguridad de tus instancias EC2 (servidores).\n",
    "- `de-c1w3-alb-sg`: Este es el grupo de seguridad del Balanceador de Carga.\n",
    "\n",
    "4.3. Haz clic en el id del grupo de seguridad con el nombre `de-c1w3-ec2-sg`. En la sección de **Reglas de entrada**, encontrarás la siguiente regla:\n",
    "\n",
    "- Regla con `Tipo: Todo TCP`, `Rango de puertos: 0-65535` y como origen un id de grupo de seguridad. Este origen es el grupo de seguridad del ALB. El propósito de este grupo de seguridad es asegurar que los servidores solo recibirán tráfico del ALB.\n",
    "\n",
    "4.4. Regresa y haz clic en el ID del grupo de seguridad `de-c1w3-alb-sg`. Verifica las **Reglas de entrada** para encontrar la siguiente regla:\n",
    "\n",
    "- Regla con `Tipo: Todo TCP`, `Rango de puertos: 0-65535` y `Origen: 0.0.0.0/0` (lo que significa todas las direcciones IP). Esta regla significa que cualquier origen puede acceder al ALB utilizando cualquier puerto, ¡lo cual es bastante abierto e inseguro!\n",
    "\n",
    "4.5. Ahora, haz clic en **Editar reglas de entrada** y elimina la regla actual. Luego, agrega una nueva regla con las siguientes propiedades:\n",
    "\n",
    "- `Rango de puertos: 80`\n",
    "- `Origen: 0.0.0.0/0`\n",
    "\n",
    "![image alt ><](./images/SecurityGroupRule.png)\n",
    "\n",
    "Guarda los cambios.\n",
    "\n",
    "Así que aunque todo internet puede tener acceso a tu ALB, el tráfico solo está permitido a través del puerto 80, por lo que si regresas a tu navegador y apuntas al puerto 90 (`<ALB-DNS>:90`) \n",
    "no deberías tener acceso a él.\n",
    "\n",
    "*Nota*: Aún puedes ver una visualización del sitio web previamente accedido a través del puerto 90 y almacenado en caché. Pero si actualizas la página web, no se cargará.\n",
    "\n",
    "Para verificar si la regla se creó correctamente, en tu navegador, apunta al puerto 80 (por defecto solo puedes poner `<ALB-DNS>` en la barra de búsqueda de tu navegador) \n",
    "y verifica si puedes ver el mensaje del Panel de control.\n",
    "\n",
    "Al configurar los grupos de seguridad, restringiste el acceso a datos sensibles presentados en el puerto 90 del ALB a personal autorizado dentro de la empresa. Esto se hizo para mejorar la seguridad general del sistema, \n",
    "siguiendo las pautas del pilar de Seguridad del Marco Bien Arquitectado de AWS y el principio de \"Priorizar la seguridad\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72728e66-199f-47f7-bc07-a8638e8b0615",
   "metadata": {},
   "source": [
    "<div id='5'/>\n",
    "\n",
    "## 5 - Verificación de disponibilidad de EC2\n",
    "\n",
    "Si revisas la arquitectura dada de la aplicación web, notarás que cada instancia de EC2 pertenece a una **Zona de Disponibilidad (AZ)** diferente. Las Zonas de Disponibilidad son centros de datos aislados, cada uno con infraestructura de energía, refrigeración y redes independientes. Diseñar aplicaciones para abarcar múltiples AZs mejora su tolerancia a fallos y resiliencia, y proporciona una base para sistemas altamente disponibles. Esta práctica en la nube está relacionada con el pilar de confiabilidad de las soluciones basadas en la nube, así como con el principio de \"Planificar para el fallo\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba450888-2a21-4156-8c88-d698393fe481",
   "metadata": {},
   "source": [
    "5.1. Para confiabilidad, nuevamente puedes poner el `Nombre DNS` en tu navegador. Pero ahora, echa un vistazo más de cerca al mensaje:\n",
    "\n",
    "```\n",
    "Datos del panel de control servidos desde el host <host-internal-ip>.ec2.internal en la zona de disponibilidad <AZ>\n",
    "```\n",
    "\n",
    "Verás una IP interna de uno de los servidores del ALB y una zona de disponibilidad. Actualiza la página y verás que tanto la IP interna como los valores de la zona de disponibilidad cambian. \n",
    "¡Eso significa que los datos se sirvieron cada vez desde diferentes zonas de disponibilidad e IP internas! ¡Imagina, que si algo sale mal con una de las AZ, tus datos aún pueden ser servidos \n",
    "desde otra!\n",
    "\n",
    "Las implementaciones Multi-AZ en AWS ofrecen a las empresas una solución robusta para mitigar el impacto de posibles fallas. Al distribuir los componentes de la aplicación en diferentes AZ, \n",
    "las organizaciones pueden lograr alta disponibilidad y tolerancia a fallas. En caso de una interrupción o problema en una AZ, el tráfico se redirige automáticamente a instancias saludables \n",
    "en otras AZ, asegurando la entrega de servicios ininterrumpida. Este enfoque arquitectónico minimiza el tiempo de inactividad, mejora el rendimiento y contribuye a una experiencia de usuario fluida.\n",
    "\n",
    "Si bien las implementaciones Multi-AZ mejoran la confiabilidad dentro de una sola región de AWS, adoptar una estrategia multi-región lleva la resiliencia al siguiente nivel. Las implementaciones \n",
    "multi-región implican replicar aplicaciones y datos en diferentes ubicaciones geográficas, ofreciendo protección contra desastres regionales, problemas geopolíticos o fallas de infraestructura. \n",
    "Este enfoque garantiza la continuidad del negocio a una escala más amplia y atiende a los usuarios globales, proporcionando acceso de baja latencia a los servicios.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627abb73-eaa8-4400-9b07-6e916eba64c9",
   "metadata": {},
   "source": [
    "<div id='6'/>\n",
    "\n",
    "## 6 - Realizando Autoescalado\n",
    "\n",
    "Necesitas asegurarte de que estás utilizando los recursos adecuadamente y de que estás adoptando el principio de \"Diseñar para la escalabilidad\" escalando hacia arriba y hacia abajo según la demanda.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae351529-f266-4ded-b01b-d3f31194eca4",
   "metadata": {},
   "source": [
    "<div id='6-1'/>\n",
    "\n",
    "### 6.1 - Utilizando Recursos de Forma Eficiente\n",
    "\n",
    "Las instancias actuales son del tipo `t3.micro` (*t* es la familia de la instancia, *3* es la generación y micro representa el tamaño de la instancia EC2).\n",
    "Te diste cuenta de que esas instancias pueden ser un poco excesivas para tu infraestructura, así que después de leer un poco más sobre los [tipos de instancias](https://aws.amazon.com/ec2/instance-types/t3/) decidiste reducir su tamaño y utilizar una instancia `t3.nano` más adecuada.\n",
    "Para escalar las instancias, necesitas modificar la forma en que se crean dentro del **Grupo de Autoescalado**, lo cual se puede hacer a través de las **Plantillas de Lanzamiento**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dae3c3-f5ea-4ff6-a6fa-f35f70a1b80b",
   "metadata": {},
   "source": [
    "6.1.1. En la consola de AWS, busca el servicio **EC2** y encuentra la sección de **Grupos de escalado automático** en el panel izquierdo. Selecciona el grupo de escalado automático proporcionado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8da47c6-08a5-4616-a76d-e17ba9fd1dab",
   "metadata": {},
   "source": [
    "6.1.2. En la pestaña **Detalles**, encuentra la sección de **Plantilla de lanzamiento** y haz clic en **Editar**.\n",
    "\n",
    "![imagen alt ><](./images/LaunchTemplateEdit.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cf7443-ed43-464f-b90f-68dffdf1ecd9",
   "metadata": {},
   "source": [
    "6.1.3. Encuentra un menú desplegable de **Versión** y debajo un enlace para `Crear una nueva versión de la plantilla de lanzamiento` (debajo de él). Esto abrirá una página para crear una nueva versión de la plantilla.\n",
    "\n",
    "![imagen alt ><](./images/CreateLaunchTemplateVersion.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff9da14-b957-48e9-9a49-beda469f25a0",
   "metadata": {},
   "source": [
    "6.1.4. Asegúrate de que la casilla de verificación **Proporcionar orientación para ayudarme a configurar una plantilla que pueda usar con EC2 Auto Scaling** esté **desmarcada**:\n",
    "\n",
    "![image alt ><](./images/TemplateCheckbox.png)\n",
    "\n",
    "En la sección **Tipo de instancia**, elige el tipo de instancia `t3.nano`:\n",
    "\n",
    "![image alt ><](./images/InstanceType.png)\n",
    "\n",
    "Desplázate hacia abajo hasta encontrar la **Configuración de red**. En la subred, haz clic en el menú desplegable y selecciona `No incluir en la plantilla de inicio`.\n",
    "\n",
    "![image alt ><](./images/AutoscalingSubnet.png)\n",
    "\n",
    "Luego, haz clic en ![](./images/CreateTemplateVersion.png).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506cb9a5-d99a-4492-873e-91ec91b999f3",
   "metadata": {},
   "source": [
    "6.1.5. Regrese a su grupo de escalado automático y luego vaya a **Detalles** > **Plantilla de lanzamiento** > **Editar**. En el menú desplegable **Versión**, ahora puede seleccionar la opción `Última` y hacer clic en el botón ![](./images/Update.png) en la parte inferior de la página.\n",
    "\n",
    "*Nota*: Si no puede utilizar la nueva plantilla y ha recibido este error\n",
    "\n",
    "![image alt ><](./images/TemplateError.png)\n",
    "\n",
    "podría ser porque no eligió la instancia EC2 correcta (`t3.nano`) en el paso 6.1.4. \n",
    "En este caso, repita los pasos 6.1.3-6.1.4 y elija `t3.nano`. \n",
    "El número debería ser `3` y el tamaño debería ser `nano`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b223b9f-c427-4fb0-b4dd-657c494f1405",
   "metadata": {},
   "source": [
    "6.1.6. Ahora, necesitas terminar las instancias para que las nuevas instancias que se lanzarán sean del tipo de instancia recién definido. En el servicio **EC2**, ve a **Instancias** y selecciona las dos que actualmente están en ejecución bajo el nombre de `de-c1w3-asg`. Haz clic derecho en cualquiera de ellas y selecciona **Terminar instancia** (o **Terminar (eliminar) instancia**). Es posible que necesites confirmar esta acción en la ventana emergente.\n",
    "\n",
    "![image alt ><](./images/TerminateInstance.png)\n",
    "\n",
    "Dado que el grupo de escalado automático tiene una capacidad deseada de 2 instancias, después de algunos minutos las nuevas instancias (con el tipo de instancia `t3.nano`) deberían comenzar a ejecutarse nuevamente. Actualiza la interfaz de usuario cada minuto hasta que aparezca como en ejecución. Antes de pasar a la siguiente sección del laboratorio, espera hasta que las instancias recién creadas tengan el estado de instancia `En ejecución`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cf7647-00f6-470a-a80d-7fcd3f860ae1",
   "metadata": {},
   "source": [
    "### 6.2 - Realización de Auto Scaling\n",
    "\n",
    "6.2.1. Las instancias de EC2 en su grupo de Auto Scaling pueden aumentar o disminuir en número dependiendo de la demanda. Con el grupo de Auto Scaling, solo paga por lo que usa. Cuando la demanda disminuye, AWS Auto Scaling eliminará automáticamente cualquier EC2 adicional para evitar gastos excesivos.\n",
    "\n",
    "Actualmente, Auto Scaling no está habilitado, por lo que el grupo de Auto Scaling no podrá escalar hacia arriba o hacia abajo. Para habilitar Auto Scaling, deberá crear una política de escalado donde necesitará especificar métricas y valores de umbral que invoquen el proceso de escalado.\n",
    "\n",
    "En la consola de AWS, regrese a la sección de **Grupos de Auto Scaling** bajo el servicio de **EC2**, elija su grupo de Auto Scaling y haga clic en la pestaña de **Escalado automático**.\n",
    "\n",
    "6.2.2. En la sección de **Políticas de escalado dinámico**, haga clic en **Crear política de escalado dinámico**.\n",
    "\n",
    "![image alt ><](./images/DynamicScalingPolicy.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936533b4-24f8-4bc7-8add-d9af9cf35351",
   "metadata": {},
   "source": [
    "6.2.3. Crear una nueva política con las siguientes propiedades:\n",
    "\n",
    "- Tipo de política: `Escalado de seguimiento de objetivo`\n",
    "- Nombre de la política de escalado: `de-c1w3-scaling-policy`\n",
    "- Tipo de métrica: `Recuento de solicitudes por objetivo del balanceador de carga de la aplicación`\n",
    "- Grupo objetivo: `de-c1w3-ec2-tg-port80`\n",
    "- Valor objetivo: `60`\n",
    "- Tiempo de calentamiento de la instancia: `60` segundos\n",
    "\n",
    "Haz clic en el botón **Crear**.\n",
    "\n",
    "El significado de esos valores es:\n",
    "- Dado que el tipo de métrica es un recuento de solicitudes por objetivo, con un valor objetivo de 60, significa que cuando el recuento de solicitudes HTTP (puerto 80) supera los 60 (valor elegido solo por simplicidad en este laboratorio), el grupo de escalado automático puede escalar para agregar más instancias para manejar la carga aumentada. Si el recuento de solicitudes por objetivo cae por debajo de 60, el grupo de escalado automático reducirá el número de instancias para ahorrar costos y mantener la eficiencia.\n",
    "\n",
    "- Un tiempo de calentamiento se refiere a un período durante el cual las instancias recién lanzadas pueden recibir tráfico e inicializarse completamente antes de considerarse en servicio para las métricas de evaluación del escalado automático. Durante el tiempo de calentamiento, el grupo de escalado automático monitorea la salud y el estado de las instancias para asegurarse de que estén listas para manejar la carga de trabajo de producción. Por simplicidad en este laboratorio, se establece este valor en 60 segundos, pero el valor predeterminado de AWS es de 300 segundos (5 minutos).\n",
    "\n",
    "6.2.4. Realiza una prueba más intensa con Apache Benchmark para probar la política de escalado que se creó. Ve a **CloudShell** y ejecuta el siguiente comando (reemplaza `ALB-DNS` con el `Nombre DNS` de tu ALB):\n",
    "\n",
    "```\n",
    "ab -n 1000000 -c 200 http://<ALB-DNS>/\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ab6463-1162-4361-98a1-69c256b9ea2f",
   "metadata": {},
   "source": [
    "Esta prueba debería ejecutarse durante algunos minutos, mientras tanto, puedes monitorear tus instancias.\n",
    "Regresa al servicio de **Grupos de escalado automático** en la consola de AWS y haz clic en **Monitoreo** y luego en **EC2** para observar nuevamente las métricas de CPU y red.\n",
    "Después de un tiempo (aproximadamente 5 min) cuando esas métricas comiencen a aumentar, puedes cambiar a la pestaña de **Actividad** y verás algunas notificaciones sobre instancias adicionales que se están lanzando para manejar el tráfico a través del puerto 80.\n",
    "\n",
    "Después de que la prueba de estrés termine, puedes seguir monitoreando las métricas y la pestaña de **Actividad** para ver cuándo las métricas vuelven a bajar y incluso las instancias lanzadas son terminadas.\n",
    "Ten en cuenta que hay cierto retraso en las gráficas de métricas en la pestaña de **Monitoreo** después de que inicias la prueba. Puedes volver a ejecutar el comando para la prueba si deseas mantener el estrés durante más tiempo.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
